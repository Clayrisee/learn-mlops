{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7e540a-8ca2-466d-8fde-ca88be523b5a",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea93aa-3ba5-4bcd-befe-4e53530b08ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac19393b-1511-4aef-8ec7-1d771ced934a",
   "metadata": {},
   "source": [
    "# Convert to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf6e6a-9adf-4108-a2e4-124c1d77b61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98d2cc02",
   "metadata": {},
   "source": [
    "## Read Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93677f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Automatically read from your env variables\n",
    "FIFTYONE_PORT = int(os.getenv(\"FIFTYONE_PORT\"))\n",
    "FIFTYONE_URI = os.getenv(\"FIFTYONE_URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f7e3d",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafaf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext(path):\n",
    "    _, file_ext = os.path.splitext(path)\n",
    "    return file_ext\n",
    "\n",
    "def read_yolo_label(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    for obj in data:\n",
    "        obj = obj.split()\n",
    "        \n",
    "        label = int(obj[0])\n",
    "        cx = float(obj[1])\n",
    "        cy = float(obj[2])\n",
    "        w = float(obj[3])\n",
    "        h = float(obj[4])\n",
    "        \n",
    "        x = cx - w/2\n",
    "        y = cy - h/2\n",
    "        \n",
    "        bbox = [x, y, w, h]\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return bboxes, labels\n",
    "\n",
    "def read_yolo_pred(path, xyxy=False):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for obj in data:\n",
    "        obj = obj.split()\n",
    "        \n",
    "        label = int(obj[0])\n",
    "        try:\n",
    "            score = float(obj[5])\n",
    "        except:\n",
    "            score = 1.0\n",
    "        \n",
    "        if xyxy:\n",
    "            x1 = int(obj[1])\n",
    "            y1 = int(obj[2])\n",
    "            x2 = int(obj[3])\n",
    "            y2 = int(obj[4])\n",
    "            \n",
    "            x = x1\n",
    "            y = y1\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "        else:\n",
    "            cx = float(obj[1])\n",
    "            cy = float(obj[2])\n",
    "            w = float(obj[3])\n",
    "            h = float(obj[4])\n",
    "\n",
    "            x = cx - w/2\n",
    "            y = cy - h/2\n",
    "        \n",
    "        bbox = [x, y, w, h]\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(label)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return bboxes, labels, scores\n",
    "\n",
    "def fo_eval_det_dataset(imgs_path, labels_path, preds_path, classes=None, name=\"eval_det\", xyxy=False):\n",
    "    samples = []\n",
    "    for img_path, label_path, pred_path in zip(imgs_path, labels_path, preds_path):\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        gt_bboxes, gt_labels = read_yolo_label(label_path)\n",
    "        pred_bboxes, pred_labels, pred_scores = read_yolo_pred(pred_path, xyxy=xyxy)\n",
    "        \n",
    "        gt_detections = [fo.Detection(label=str(label), bounding_box=bbox) for label, bbox in zip(gt_labels, gt_bboxes)]\n",
    "        pred_detections = [fo.Detection(label=str(label), bounding_box=bbox, confidence=score) for label, bbox, score in zip(pred_labels, pred_bboxes, pred_scores)]\n",
    "        \n",
    "        sample[\"ground_truth\"] = fo.Detections(detections=gt_detections)\n",
    "        sample[\"predictions\"] = fo.Detections(detections=pred_detections)\n",
    "        samples.append(sample)\n",
    "\n",
    "    print(f'{len(samples)} images found')\n",
    "    \n",
    "    # Create dataset\n",
    "    # fo.core.dataset.delete_dataset(name, verbose=True)\n",
    "    # dataset = fo.Dataset(name, overwrite=True)\n",
    "    # fo.delete_non_persistent_datasets(verbose=True)\n",
    "    dataset = fo.Dataset(name, overwrite=True)\n",
    "    dataset.add_samples(samples)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc26425",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b70457",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = \"YOUR-IMAGE-DIRECTORY\"\n",
    "labels_dir = \"GT-LABELS-IMG-PATH\"\n",
    "preds_dir = \"PREDS-LABELS-IMG-PATH\"\n",
    "\n",
    "txt_exts = [\".txt\"]\n",
    "imgs_path = sorted([img_path for img_path in sorted(glob.glob(f\"{imgs_dir}/**/*.*\", recursive=True)) if ext(img_path) not in txt_exts])\n",
    "labels_path = sorted([label_path for label_path in sorted(glob.glob(f\"{labels_dir}/**/*.*\", recursive=True)) if ext(label_path) in txt_exts])\n",
    "preds_path = sorted([pred_path for pred_path in sorted(glob.glob(f\"{preds_dir}/**/*.*\", recursive=True)) if ext(pred_path) in txt_exts])\n",
    "\n",
    "assert len(imgs_path)==len(labels_path)\n",
    "assert len(labels_path)==len(preds_path)\n",
    "\n",
    "# fiftyone dataset\n",
    "dataset = fo_eval_det_dataset(imgs_path, labels_path, preds_path, name=\"train_dataset_helmet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3bd21f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7774a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Load zoo model\n",
    "model = foz.load_zoo_model(\"resnext50-32x4d-imagenet-torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf600c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embeddings = dataset.compute_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches_embeddings = dataset.compute_patch_embeddings(model, patches_field=\"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"full_frame_embeddings.npy\", img_embeddings)\n",
    "# np.save(\"patches_embeddings.npy\", patches_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31435632",
   "metadata": {},
   "source": [
    "## Visualize Embedding Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd83079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.core.utils as fou\n",
    "\n",
    "def compute_visualization_classification(\n",
    "    dataset,\n",
    "    embeddings,\n",
    "    method=\"umap\",\n",
    "    brain_key=\"umap_embeddings\",\n",
    "    ):\n",
    "    # Compute 2D representation using pre-computed embeddings\n",
    "    viz_results = fob.compute_visualization(\n",
    "        dataset,\n",
    "        embeddings=embeddings,\n",
    "        num_dims=2,\n",
    "        method=method,\n",
    "        brain_key=brain_key,\n",
    "        verbose=True,\n",
    "        seed=51)\n",
    "    return viz_results\n",
    "\n",
    "def compute_visualization_detection(\n",
    "    dataset,\n",
    "    embeddings,\n",
    "    patches_field=\"ground_truth\"\n",
    "        ):\n",
    "    # Compute 2D representation using pre-computed embeddings\n",
    "    viz_results = fob.compute_visualization(\n",
    "        dataset,\n",
    "        patches_field=patches_field,\n",
    "        embeddings=embeddings,\n",
    "        num_dims=2,\n",
    "        brain_key=\"image_embeddings\",\n",
    "        verbose=True,\n",
    "        seed=51)\n",
    "    return viz_results\n",
    "\n",
    "def compute_uniqueness(dataset, embeddings):\n",
    "    fob.compute_uniqueness(dataset, embeddings=embeddings)\n",
    "    dataset.sort_by(\"uniqueness\", reverse=True)\n",
    "    return dataset\n",
    "\n",
    "def plot_img_embedding(viz_result, labels=\"unlabeled\"):\n",
    "    plot = viz_result.visualize(labels=labels)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c436d11",
   "metadata": {},
   "source": [
    "## Plot Full Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_viz_results = compute_visualization_classification(dataset, img_embeddings, method=\"tsne\", brain_key=\"tsne_img_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc20b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_frame = plot_img_embedding(full_viz_results, labels=\"full_frame\")\n",
    "fo.close_app()\n",
    "plot_full_frame.show()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_full_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_frame = plot_img_embedding(full_viz_results, labels=\"full_frame\")\n",
    "fo.close_app()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_full_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf485fa4",
   "metadata": {},
   "source": [
    "## Compute Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa686bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_viz_results = compute_visualization_detection(dataset, patches_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patches_embd = plot_img_embedding(patches_viz_results, labels=\"ground_truth.detections\")\n",
    "fo.close_app()\n",
    "plot_patches_emb.show()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_patches_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345cee",
   "metadata": {},
   "source": [
    "## Compute Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = compute_uniqueness(dataset, img_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.close_app()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d392d3",
   "metadata": {},
   "source": [
    "## Compute Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_results = fob.compute_similarity(\n",
    "    dataset, model=\"resnext50-32x4d-imagenet-torch\", patches_field=\"ground_truth\", brain_key=\"gt_sim\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da442d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.compute_similarity(\n",
    "    dataset, model=\"resnext50-32x4d-imagenet-torch\", brain_key=\"gt_sim_img\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333bd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataset = dataset\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    ")\n",
    "\n",
    "# Print a classification report for the classes\n",
    "results.print_report()\n",
    "\n",
    "# Print some statistics about the total TP/FP/FN counts\n",
    "print(\"TP: %d\" % dataset.sum(\"eval_tp\"))\n",
    "print(\"FP: %d\" % dataset.sum(\"eval_fp\"))\n",
    "print(\"FN: %d\" % dataset.sum(\"eval_fn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f7114",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, percentage=0.25):\n",
    "    temp_dataset = dataset.clone()\n",
    "    test_size = int(len(dataset) * percentage)\n",
    "    test_samples = temp_dataset.take(test_size)\n",
    "    temp_dataset.delete_samples(test_samples)\n",
    "    test_dataset = test_samples.clone()\n",
    "    test_dataset.persistent = True\n",
    "    temp_dataset.persistent = True\n",
    "    return temp_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d74e9",
   "metadata": {},
   "source": [
    "### Case Bonceng Anak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonceng_anak_view = dataset.match_tags(\"bonceng_tiga_anak\")\n",
    "fp_case_dataset  = bonceng_anak_view.clone()\n",
    "fp_case_dataset.persistent = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ccb3f",
   "metadata": {},
   "source": [
    "## Split Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20894cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dataset_samples = dataset.match(F(\"uniqueness\") > 0.6)\n",
    "common_dataset_samples = dataset.match(F(\"uniqueness\") < 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d487e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dataset_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d71e43",
   "metadata": {},
   "source": [
    "## Your Custom Preprocessing Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79911fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
