{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98d2cc02",
   "metadata": {},
   "source": [
    "## Read Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93677f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Automatically read from your env variables\n",
    "FIFTYONE_PORT = int(os.getenv(\"FIFTYONE_PORT\", 5151))\n",
    "FIFTYONE_URI = os.getenv(\"FIFTYONE_URI\", \"0.0.0.0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e11f7e3d",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61829652-8f0c-4e1f-a126-2636897c64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "def ext(path):\n",
    "    _, file_ext = os.path.splitext(path)\n",
    "    return file_ext\n",
    "\n",
    "def read_yolo_label(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    for obj in data:\n",
    "        obj = obj.split()\n",
    "        \n",
    "        label = int(obj[0])\n",
    "        cx = float(obj[1])\n",
    "        cy = float(obj[2])\n",
    "        w = float(obj[3])\n",
    "        h = float(obj[4])\n",
    "        \n",
    "        x = cx - w/2\n",
    "        y = cy - h/2\n",
    "        \n",
    "        bbox = [x, y, w, h]\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return bboxes, labels\n",
    "\n",
    "def read_yolo_pred(path, xyxy=False):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for obj in data:\n",
    "        obj = obj.split()\n",
    "        \n",
    "        label = int(obj[0])\n",
    "        try:\n",
    "            score = float(obj[5])\n",
    "        except:\n",
    "            score = 1.0\n",
    "        \n",
    "        if xyxy:\n",
    "            x1 = int(obj[1])\n",
    "            y1 = int(obj[2])\n",
    "            x2 = int(obj[3])\n",
    "            y2 = int(obj[4])\n",
    "            \n",
    "            x = x1\n",
    "            y = y1\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "        else:\n",
    "            cx = float(obj[1])\n",
    "            cy = float(obj[2])\n",
    "            w = float(obj[3])\n",
    "            h = float(obj[4])\n",
    "\n",
    "            x = cx - w/2\n",
    "            y = cy - h/2\n",
    "        \n",
    "        bbox = [x, y, w, h]\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(label)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return bboxes, labels, scores\n",
    "\n",
    "def create_dataset(imgs_path, labels_path, classes=None, name=\"eval_det\", xyxy=False):\n",
    "    samples = []\n",
    "    for img_path, label_path in zip(imgs_path, labels_path):\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        gt_bboxes, gt_labels = read_yolo_label(label_path)\n",
    "        gt_detections = [fo.Detection(label=str(label), bounding_box=bbox) for label, bbox in zip(gt_labels, gt_bboxes)]\n",
    "        sample[\"ground_truth\"] = fo.Detections(detections=gt_detections)\n",
    "        samples.append(sample)\n",
    "    print(f'{len(samples)} images found')\n",
    "    # Create dataset\n",
    "    dataset = fo.Dataset(name, overwrite=True)\n",
    "    dataset.add_samples(samples)\n",
    "    return dataset\n",
    "\n",
    "def fo_eval_det_dataset(imgs_path, labels_path, preds_path, classes=None, name=\"eval_det\", xyxy=False):\n",
    "    samples = []\n",
    "    for img_path, label_path, pred_path in zip(imgs_path, labels_path, preds_path):\n",
    "        sample = fo.Sample(filepath=img_path)\n",
    "        gt_bboxes, gt_labels = read_yolo_label(label_path)\n",
    "        pred_bboxes, pred_labels, pred_scores = read_yolo_pred(pred_path, xyxy=xyxy)\n",
    "        \n",
    "        gt_detections = [fo.Detection(label=str(label), bounding_box=bbox) for label, bbox in zip(gt_labels, gt_bboxes)]\n",
    "        pred_detections = [fo.Detection(label=str(label), bounding_box=bbox, confidence=score) for label, bbox, score in zip(pred_labels, pred_bboxes, pred_scores)]\n",
    "        \n",
    "        sample[\"ground_truth\"] = fo.Detections(detections=gt_detections)\n",
    "        sample[\"predictions\"] = fo.Detections(detections=pred_detections)\n",
    "        samples.append(sample)\n",
    "\n",
    "    print(f'{len(samples)} images found')\n",
    "    \n",
    "    # Create dataset\n",
    "    # fo.core.dataset.delete_dataset(name, verbose=True)\n",
    "    # dataset = fo.Dataset(name, overwrite=True)\n",
    "    # fo.delete_non_persistent_datasets(verbose=True)\n",
    "    dataset = fo.Dataset(name, overwrite=True)\n",
    "    dataset.add_samples(samples)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dc26425",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07df2d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224 images found\n",
      " 100% |███████████████| 9224/9224 [17.8s elapsed, 0s remaining, 416.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "imgs_dir = \"IVTXX17BBXX191024-01_Vehicle Detection Short Distance 5 & 17 Classes Dataset/images\"\n",
    "labels_dir = \"IVTXX17BBXX191024-01_Vehicle Detection Short Distance 5 & 17 Classes Dataset/labels\"\n",
    "\n",
    "txt_exts = [\".txt\"]\n",
    "imgs_path = sorted([img_path for img_path in sorted(glob.glob(f\"{imgs_dir}/**/*.*\", recursive=True)) if ext(img_path) not in txt_exts])\n",
    "labels_path = sorted([label_path for label_path in sorted(glob.glob(f\"{labels_dir}/**/*.*\", recursive=True)) if ext(label_path) in txt_exts])\n",
    "\n",
    "assert len(imgs_path)==len(labels_path)\n",
    "\n",
    "# fiftyone dataset\n",
    "dataset = create_dataset(imgs_path, labels_path, name=\"vehicle_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3cc734-2c27-4048-8bff-0e5f7d305528",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b75f62-10c7-40da-ba90-47ea7e0eb83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name:        vehicle_dataset\n",
       "Media type:  image\n",
       "Num samples: 9224\n",
       "Persistent:  True\n",
       "Tags:        []\n",
       "Sample fields:\n",
       "    id:           fiftyone.core.fields.ObjectIdField\n",
       "    filepath:     fiftyone.core.fields.StringField\n",
       "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
       "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = fo.load_dataset(\"vehicle_dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f0b03f-fe12-4309-8622-27956efd4d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://0.0.0.0:5151/?notebook=True&subscription=bde904b1-0e3f-463d-aa02-7397d63f4c93\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdc0975e910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de3bd21f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7774a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth'...\n",
      " 100% |████|  766.3Mb/766.3Mb [13.5s elapsed, 0s remaining, 66.3Mb/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 95.8M/95.8M [00:13<00:00, 7.36MB/s]\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Load zoo model\n",
    "model = foz.load_zoo_model(\"resnext50-32x4d-imagenet-torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf600c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embeddings = dataset.compute_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"full_frame_embeddings.npy\", img_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31435632",
   "metadata": {},
   "source": [
    "## Visualize Embedding Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd83079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.core.utils as fou\n",
    "\n",
    "def compute_visualization_classification(\n",
    "    dataset,\n",
    "    embeddings,\n",
    "    method=\"umap\",\n",
    "    brain_key=\"umap_embeddings\",\n",
    "    ):\n",
    "    # Compute 2D representation using pre-computed embeddings\n",
    "    viz_results = fob.compute_visualization(\n",
    "        dataset,\n",
    "        embeddings=embeddings,\n",
    "        num_dims=2,\n",
    "        method=method,\n",
    "        brain_key=brain_key,\n",
    "        verbose=True,\n",
    "        seed=51)\n",
    "    return viz_results\n",
    "\n",
    "def compute_visualization_detection(\n",
    "    dataset,\n",
    "    embeddings,\n",
    "    patches_field=\"ground_truth\"\n",
    "        ):\n",
    "    # Compute 2D representation using pre-computed embeddings\n",
    "    viz_results = fob.compute_visualization(\n",
    "        dataset,\n",
    "        patches_field=patches_field,\n",
    "        embeddings=embeddings,\n",
    "        num_dims=2,\n",
    "        brain_key=\"image_embeddings\",\n",
    "        verbose=True,\n",
    "        seed=51)\n",
    "    return viz_results\n",
    "\n",
    "def compute_uniqueness(dataset, embeddings):\n",
    "    fob.compute_uniqueness(dataset, embeddings=embeddings)\n",
    "    dataset.sort_by(\"uniqueness\", reverse=True)\n",
    "    return dataset\n",
    "\n",
    "def plot_img_embedding(viz_result, labels=\"unlabeled\"):\n",
    "    plot = viz_result.visualize(labels=labels)\n",
    "    return plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c436d11",
   "metadata": {},
   "source": [
    "## Plot Full Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_viz_results = compute_visualization_classification(dataset, img_embeddings, method=\"tsne\", brain_key=\"tsne_img_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc20b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_frame = plot_img_embedding(full_viz_results, labels=\"full_frame\")\n",
    "fo.close_app()\n",
    "plot_full_frame.show()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_full_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_frame = plot_img_embedding(full_viz_results, labels=\"full_frame\")\n",
    "fo.close_app()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_full_frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf485fa4",
   "metadata": {},
   "source": [
    "## Compute Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa686bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_viz_results = compute_visualization_detection(dataset, patches_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patches_embd = plot_img_embedding(patches_viz_results, labels=\"ground_truth.detections\")\n",
    "fo.close_app()\n",
    "plot_patches_emb.show()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)\n",
    "session.plots.attach(plot_patches_embd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30345cee",
   "metadata": {},
   "source": [
    "## Compute Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = compute_uniqueness(dataset, img_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.close_app()\n",
    "session = fo.launch_app(dataset, port=FIFTYONE_PORT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2d392d3",
   "metadata": {},
   "source": [
    "## Compute Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_results = fob.compute_similarity(\n",
    "    dataset, model=\"resnext50-32x4d-imagenet-torch\", patches_field=\"ground_truth\", brain_key=\"gt_sim\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da442d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.compute_similarity(\n",
    "    dataset, model=\"resnext50-32x4d-imagenet-torch\", brain_key=\"gt_sim_img\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333bd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataset = dataset\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    ")\n",
    "\n",
    "# Print a classification report for the classes\n",
    "results.print_report()\n",
    "\n",
    "# Print some statistics about the total TP/FP/FN counts\n",
    "print(\"TP: %d\" % dataset.sum(\"eval_tp\"))\n",
    "print(\"FP: %d\" % dataset.sum(\"eval_fp\"))\n",
    "print(\"FN: %d\" % dataset.sum(\"eval_fn\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a07f7114",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, percentage=0.25):\n",
    "    temp_dataset = dataset.clone()\n",
    "    test_size = int(len(dataset) * percentage)\n",
    "    test_samples = temp_dataset.take(test_size)\n",
    "    temp_dataset.delete_samples(test_samples)\n",
    "    test_dataset = test_samples.clone()\n",
    "    test_dataset.persistent = True\n",
    "    temp_dataset.persistent = True\n",
    "    return temp_dataset, test_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a5ccb3f",
   "metadata": {},
   "source": [
    "## Split Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20894cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dataset_samples = dataset.match(F(\"uniqueness\") > 0.6)\n",
    "common_dataset_samples = dataset.match(F(\"uniqueness\") < 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d487e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dataset_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d71e43",
   "metadata": {},
   "source": [
    "## Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f24b2-d07c-4903-989c-08ba2444dd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
